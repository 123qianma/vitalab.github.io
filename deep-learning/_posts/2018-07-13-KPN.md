---
layout: review
title: Burst Denoising with Kernel Prediction Networks
tags: deep-learning CNN
author: "Daniel JÃ¶rgens"
cite:
    authors: "Mildenhall, B and Barron, J T and Chen, J and Sharlet, D and Ng, R and Carroll, R"
    title:   "Burst Denoising with Kernel Prediction Networks"
    venue:   "arxiv.org"
pdf: "https://arxiv.org/pdf/1712.02327.pdf"
---

# Goal

The presented approach aims at learning a set of filters for denoising bursts of images taken
by hand-held cameras (e.g. in smartphones).


# Contributions

 * ...


# Conceptual overview

<p style="text-align:center"><img src="/deep-learning/images/KPN/overview.png" width="750"></p>

#### Basic concept

 * **input**
 
   * set of series of _N_ images (burst)
   * one image of pixel-wise noise estimates

 * encoder-decoder structure
 
 * **output**
 
   * _N_ filters per pixel in input space (filter size: _K_ by _K_)
   * synthesis of output image at pixel _p_ by
   
   <p style="text-align:center"><img src="/deep-learning/images/KPN/synthesis.png" width="250"></p>
   
      (_f^p_i_: learned filter at pixel _p_ in input image _i_)

#### Loss

 * *main* objective
 
   * L2 term on gamma-corrected images
   * L1 term on gradients of gamma-corrected images
 
   <p style="text-align:center"><img src="/deep-learning/images/KPN/main_objective.png" width="500"></p>

 * *annealed* loss (This is the actual loss term!)
 
   * time dependent _individual image_ loss term
   * **idea**: steer training in the beginning to avoid convergence to local minima
   
   <p style="text-align:center"><img src="/deep-learning/images/KPN/actual_loss.png" width="500"></p>

#### Synthetic data creation

 * explicit model for signal noise
 
   <p style="text-align:center"><img src="/deep-learning/images/KPN/noise_levels.png" width="500"></p>

 * simulated misalignment


# Experiments

#### Settings

 * filter size: _K_ = 5
 * number of input images: _N_ = 8

#### Nomenclature (KPN methods)

 * _1-frame_: _N_ = 1
 * _no ann_: basic loss function only (@see *main* objective)
 * _sigma blind_: no noise estimate as input
 * _direct_: directly synthesise output pixel values (by adding three additional conv layers)

#### Synthetic data set

 * _KPN_ always outperforms state of the art
 * multi-frame info, annealing loss and noise estimate are all helpful

   <p style="text-align:center"><img src="/deep-learning/images/KPN/synthetic_1.png" width="500"></p>

#### Predicted kernels

 * The approach is robust to object movement (the mouse).
 * The authors claim that their 'annealing' approach helps focusing on a single frame where movement occurs,
   while taking advantage of all frames in static parts of the image (i.e. background).

   <p style="text-align:center"><img src="/deep-learning/images/KPN/predicted_kernels.png" width="500"></p>

#### Adaption to noise levels

 * Noise estimation
 
   * did not improve training loss
   * but helps for **generalisation** to larger (unseen) noise levels

 * Learned filters adapt to the _noise estimate_ in the input
 
   * (a) to (e): scalar multiples of _noise estimate_ for same image burst
 
   <p style="text-align:center"><img src="/deep-learning/images/KPN/noise_adaption.png" width="700"></p>
 
