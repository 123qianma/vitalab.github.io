---
layout: review
title:  "Scale-Aware Face Detection"
tags:   deep-learning CNN
author: Cl√©ment Zotti
pdf:   "https://arxiv.org/pdf/1706.09876.pdf"

cite:

  authors: "H.Zekun,L.Yu, Q.Hongwei, Y.Junjie, L.Xiu, H.Xiaolin"
  title:   "Scale-Aware Face Detection"
  venue:   "CVPR 2017"
---

This paper address a face detection problem and test their model on three face detection datasets, Face Detection Data Set and Benchmark ([FDDB](http://vis-www.cs.umass.edu/fddb/){:target="_blank"}), Multi-Attribute Labelled Faces ([MALF](http://www.cbsr.ia.ac.cn/faceevaluation/){:target="_blank"}) and Face Detection, Pose Estimation and Landmark Localization in the Wild ([AFW](http://www.ics.uci.edu/~xzhu/face/){:target="_blank"}).


## Models

They split the problem in two smaller one. They use a network to detect the scale of faces in the image and another one to place boundingbox on these faces.

### Scale Proposal Network (SPN)

First, they use a CNN model (SPN) to predict an historgram of scales of faces in the images, as shown in Fig.3.

![](/deep-learning/images/safd/spn.png)

They refine the prediction of the SPN by smoothing it with a moving average and use the non max supression algorithm to have fewer scales as shown in Fig.4.

<div align="middle">
     <img src="/deep-learning/images/safd/spn_refined.png">
</div>

### Region Proposal Network (RPN)

Finally, after the proposals produced by the SPN, they rescale the image given the scaling histogram and predict the boundingbox face for all the rescaled images with the Single Scale RPN as in Fig.2.

![](/deep-learning/images/safd/safd_pipeline.png){:align="middle"}

The RPN is the Faster r-cnn model ([paper](https://arxiv.org/abs/1506.01497), [code](https://github.com/ShaoqingRen/faster_rcnn)). The inner network for these two models is made from [GoogleNet](https://arxiv.org/abs/1409.4842).

## Training

They generate the bounding box from keys points in faces to avoid the noise added when doing manual bounding box annotation. The keys points are left eye center, right eye center, nose, left mouth corner and right mouth corner. Each bounding box generated are square.

For the scaling vector used in the SPN they use a gaussian function centered on the ground truth face size.

## Results

They report SOTA results on the three datasets with a **mean recal rate** of **88.15%** and an **average precision** of **98.77%**.
