---
layout: review
title:  "Multisource and Multitemporal Data Fusion in Remote Sensing"
tags:   deep-learning segmentation remote-sensing CNN hyperspectral multi-task-learning point-cloud
author: Charles Authier
pdf:  https://arxiv.org/pdf/1812.08287.pdf
cite:
    authors: "Pedram Ghamisi, Behnood Rasti, Naoto Yokoya, Qunming Wang, Bernhard Hofle, Lorenzo Bruzzone, Francesca Bovolo, Mingmin Chi, Katharina Anders, Richard Gloaguen, Peter M. Atkinson, Jon Atli Benediktsson"
    title:   "Multisource and Multitemporal Data Fusion in Remote Sensing"
    venue:   "arXiv preprint arXiv:1812.08287. 2018 Dec 19."
---

*KEYS WORDS: light detection and ranging (LiDAR), terrestrial laser scanning (TLS), synthetic aperture radar (SAR), Gravity Recovery And Climate Experiment (GRACE), Medium Resolution Imaging Spectrometer (MERIS), electromagnetic spectrum (EMS) *


This paper brings together the advances of multisource and multitemporal data fusion approaches with different research communities and provides a thorough and discipline-specific starting point for researchers at different levels.
More specifically, it provides an overview of many important contributions dedicated to the topics of pansharpening and resolution enhancement, point cloud data fusion, hyperspectral and LiDAR data fusion, multitemporal data fusion, as well as big data and social media.

The remote sensors onboard the multiples platforms may vary greatly in multiple dimensions.
For example, the types of properties sensed and the spatial and spectral resolutions of the data.

![](/article/images/mmdfrs/fig1.png)

## Spatio-spectral fusion
*  Component Substitution
* Multiresolution Analysis
* Geostatistical Analysis
* Subspace Representation
* Sparse Representation

## Spatio-temporal fusion
* The spatial and temporal adaptive reflectance fusion model(STARFM).
* For heterogeneous landscapes, an enhanced STARFM (ESTARFM).

![](/article/images/mmdfrs/fig2.png)

## Point Cloud
* Point cloud level: Enrich the initial point cloud P with new point features.
* Image/Voxel level: Derive new image layers representing 3D point cloud information.
* Feature level: Fusion of point cloud information on the segment/object level.

![](/article/images/mmdfrs/fig6.png)

## Hyperspectral and LiDAR

![](/article/images/mmdfrs/fig78.png)

## Deep Learning

![](/article/images/mmdfrs/fig10.png)

## Fusion

![](/article/images/mmdfrs/fig14.png)

![](/article/images/mmdfrs/table3.png)

## Conclusion
The field of multisensor and multitemporal data fusion for remotely sensed imagery is enormous.
This article focuses particularly on advances in multisource and multitemporal data fusion approaches with respect to different research communities since the methods for the fusion of different modalities have expand.
In fusion topics, including pansharpening and resolution enhancement, point cloud data fusion, hyperspectral and LiDAR data fusion, multitemporal data fusion, as well as big data and social media.

